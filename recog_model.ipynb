{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate test / train split\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, seq_len, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.seq_len)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.seq_len\n",
    "        end_idx = (idx + 1) * self.seq_len\n",
    "\n",
    "        batch_x = self.x[start_idx:end_idx]\n",
    "        batch_y = self.y[start_idx:end_idx]\n",
    "\n",
    "        batch_x = torch.from_numpy(batch_x)\n",
    "        batch_y = torch.from_numpy(batch_y)\n",
    "        \n",
    "        # Pad sequences to ensure they have the same length within the batch\n",
    "        pad_len = self.seq_len - batch_x.shape[0]\n",
    "        if pad_len > 0:\n",
    "            pad_shape = (pad_len,) + batch_x.shape[1:]\n",
    "            pad_shape_y = (pad_len,) + batch_y.shape[1:]\n",
    "            \n",
    "            batch_x = torch.cat([batch_x, torch.zeros(pad_shape)], dim=0)\n",
    "            batch_y = torch.cat([batch_y, torch.zeros(pad_shape_y)], dim=0)\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        indices = np.arange(len(self.x))\n",
    "        np.random.shuffle(indices)\n",
    "        self.x = self.x[indices]\n",
    "        self.y = self.y[indices]\n",
    "        \n",
    "def generate_data_split(subject_id):\n",
    "    # Get CSV files list from a folder\n",
    "    train_path = './Train'\n",
    "    test_path = './Test'\n",
    "    \n",
    "    csv_path = './ProcessedDatasets/Knot_Tying'\n",
    "    \n",
    "    csv_files = glob.glob(csv_path + \"/*.csv\")\n",
    "    \n",
    "    train_df_list = []\n",
    "    test_df_list = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        if(subject_id in file):\n",
    "            test_df_list.append(pd.read_csv(file))\n",
    "#             print(file)\n",
    "        else:\n",
    "            train_df_list.append(pd.read_csv(file))\n",
    "            \n",
    "\n",
    "    print('Train Subject Trials: ',len(train_df_list))\n",
    "    print('Test Subject Trials: ',len(test_df_list))\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    train_df   = pd.concat(train_df_list, ignore_index=True)\n",
    "    test_df   = pd.concat(test_df_list, ignore_index=True)\n",
    "\n",
    "    \n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "    train_labels= train_df.pop('label')\n",
    "    train_features = train_df\n",
    "\n",
    "    test_labels= test_df.pop('label')\n",
    "    test_features = test_df\n",
    "\n",
    "\n",
    "    all_class_names = [\"G1\", 'G2', 'G3', 'G4', 'G5', 'G6', 'G8', 'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15']\n",
    "    lb.fit(all_class_names)\n",
    "\n",
    "    train_labels = lb.transform(train_labels)\n",
    "    test_labels = lb.transform(test_labels)\n",
    "    \n",
    "    train_x = train_features.to_numpy()\n",
    "    train_y = train_labels\n",
    "\n",
    "    test_x = test_features.to_numpy()\n",
    "    test_y = test_labels\n",
    "\n",
    "    seq_len = 30\n",
    "    batch_size = 64\n",
    "\n",
    "    train_dataset = CustomDataset(train_x, train_y, seq_len, batch_size)\n",
    "    test_dataset = CustomDataset(test_x, test_y, seq_len, batch_size)\n",
    "\n",
    "    train_dataloader = tf.data.Dataset.from_generator(\n",
    "        lambda: train_dataset,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=( seq_len, train_x.shape[1]), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=( seq_len, train_y.shape[1]), dtype=tf.float32),\n",
    "        ),\n",
    "    # )\n",
    "    ).repeat()\n",
    "    train_dataloader = train_dataloader.batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    test_dataloader = tf.data.Dataset.from_generator(\n",
    "        lambda: test_dataset,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=( seq_len, test_x.shape[1]), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=( seq_len, test_y.shape[1]), dtype=tf.float32),\n",
    "        ),\n",
    "    )\n",
    "    test_dataloader = test_dataloader.batch(batch_size)\n",
    "    \n",
    "    return train_dataloader, test_dataloader\n",
    "    \n",
    "# subjects = ['S02','S03','S04','S05','S06','S07','S08','S09']\n",
    "\n",
    "# for subject in subjects:\n",
    "#     generate_data_split(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Get CSV files list from a folder\n",
    "# train_path = './Train'\n",
    "# test_path = './Test'\n",
    "# train_csv_files = glob.glob(train_path + \"/*.csv\")\n",
    "# test_csv_files = glob.glob(test_path + \"/*.csv\")\n",
    "\n",
    "# # Read each CSV file into DataFrame\n",
    "# # This creates a list of dataframes\n",
    "# train_df_list = (pd.read_csv(file) for file in train_csv_files)\n",
    "# test_df_list = (pd.read_csv(file) for file in test_csv_files)\n",
    "\n",
    "# # Concatenate all DataFrames\n",
    "# train_df   = pd.concat(train_df_list, ignore_index=True)\n",
    "# test_df   = pd.concat(test_df_list, ignore_index=True)\n",
    "\n",
    "# lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "# train_labels= train_df.pop('label')\n",
    "# train_features = train_df\n",
    "\n",
    "# test_labels= test_df.pop('label')\n",
    "# test_features = test_df\n",
    "\n",
    "\n",
    "# all_class_names = [\"G1\", 'G2', 'G3', 'G4', 'G5', 'G6', 'G8', 'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15']\n",
    "# lb.fit(all_class_names)\n",
    "\n",
    "# train_labels = lb.transform(train_labels)\n",
    "# test_labels = lb.transform(test_labels)\n",
    "\n",
    "\n",
    "# # seq_len = 30\n",
    "# # batch_size = 30\n",
    "\n",
    "# # class DataGenerator(Sequence):\n",
    "# #     def __init__(self, x_set, y_set, batch_size):\n",
    "# #         self.x, self.y = x_set, y_set\n",
    "# #         self.batch_size = batch_size\n",
    "\n",
    "# #     def __len__(self):\n",
    "# #         return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "# #     def __getitem__(self, idx):\n",
    "# #         batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "# #         batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "# #         return batch_x, batch_y\n",
    "\n",
    "# # train_gen = DataGenerator(train_features, train_labels, batch_size)\n",
    "# # test_gen = DataGenerator(test_features, test_labels, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, x_set, y_set, seq_len):\n",
    "#         self.x, self.y = x_set, y_set\n",
    "#         self.seq_len = seq_len\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return int(np.ceil(len(self.x) / float(self.seq_len)))\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         batch_x = self.x[idx * self.seq_len:(idx + 1) * self.seq_len]\n",
    "#         batch_y = self.y[idx * self.seq_len:(idx + 1) * self.seq_len]\n",
    "#         batch_x = torch.from_numpy(batch_x)\n",
    "#         batch_y = torch.from_numpy(batch_y)\n",
    "#         return batch_x, batch_y\n",
    "    \n",
    "# train_x = train_features.to_numpy()\n",
    "# train_y = train_labels\n",
    "    \n",
    "# test_x = test_features.to_numpy()\n",
    "# test_y = test_labels\n",
    "\n",
    "# seq_len = 30\n",
    "# batch_size = 1\n",
    "\n",
    "\n",
    "# train_dataset = CustomDataset(train_x, train_y, seq_len)\n",
    "# test_dataset = CustomDataset(test_x, test_y, seq_len)\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# class CustomDataset(tf.keras.utils.Sequence):\n",
    "#     def __init__(self, x_set, y_set, seq_len, batch_size):\n",
    "#         self.x, self.y = x_set, y_set\n",
    "#         self.seq_len = seq_len\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return int(np.ceil(len(self.x) / float(self.seq_len)))\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         start_idx = idx * self.seq_len\n",
    "#         end_idx = (idx + 1) * self.seq_len\n",
    "\n",
    "#         batch_x = self.x[start_idx:end_idx]\n",
    "#         batch_y = self.y[start_idx:end_idx]\n",
    "\n",
    "#         batch_x = torch.from_numpy(batch_x)\n",
    "#         batch_y = torch.from_numpy(batch_y)\n",
    "        \n",
    "#         # Pad sequences to ensure they have the same length within the batch\n",
    "#         pad_len = self.seq_len - batch_x.shape[0]\n",
    "#         if pad_len > 0:\n",
    "#             pad_shape = (pad_len,) + batch_x.shape[1:]\n",
    "#             pad_shape_y = (pad_len,) + batch_y.shape[1:]\n",
    "            \n",
    "#             batch_x = torch.cat([batch_x, torch.zeros(pad_shape)], dim=0)\n",
    "#             batch_y = torch.cat([batch_y, torch.zeros(pad_shape_y)], dim=0)\n",
    "\n",
    "#         return batch_x, batch_y\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         indices = np.arange(len(self.x))\n",
    "#         np.random.shuffle(indices)\n",
    "#         self.x = self.x[indices]\n",
    "#         self.y = self.y[indices]\n",
    "\n",
    "# train_x = train_features.to_numpy()\n",
    "# train_y = train_labels\n",
    "\n",
    "# test_x = test_features.to_numpy()\n",
    "# test_y = test_labels\n",
    "\n",
    "# seq_len = 30\n",
    "# batch_size = 64\n",
    "\n",
    "# train_dataset = CustomDataset(train_x, train_y, seq_len, batch_size)\n",
    "# test_dataset = CustomDataset(test_x, test_y, seq_len, batch_size)\n",
    "\n",
    "# train_dataloader = tf.data.Dataset.from_generator(\n",
    "#     lambda: train_dataset,\n",
    "#     output_signature=(\n",
    "#         tf.TensorSpec(shape=( seq_len, train_x.shape[1]), dtype=tf.float32),\n",
    "#         tf.TensorSpec(shape=( seq_len, train_y.shape[1]), dtype=tf.float32),\n",
    "#     ),\n",
    "# # )\n",
    "# ).repeat()\n",
    "# train_dataloader = train_dataloader.batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# test_dataloader = tf.data.Dataset.from_generator(\n",
    "#     lambda: test_dataset,\n",
    "#     output_signature=(\n",
    "#         tf.TensorSpec(shape=( seq_len, test_x.shape[1]), dtype=tf.float32),\n",
    "#         tf.TensorSpec(shape=( seq_len, test_y.shape[1]), dtype=tf.float32),\n",
    "#     ),\n",
    "# )\n",
    "# test_dataloader = test_dataloader.batch(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_data_split(subject_id):\n",
    "#     # Get CSV files list from a folder\n",
    "#     train_path = './Train'\n",
    "#     test_path = './Test'\n",
    "    \n",
    "#     csv_path = './Dataset'\n",
    "    \n",
    "#     csv_files = glob.glob(csv_path + \"/*.csv\")\n",
    "    \n",
    "#     train_df_list = []\n",
    "#     test_df_list = []\n",
    "    \n",
    "#     for file in csv_files:\n",
    "#         if(subject_id in file):\n",
    "#             test_df_list.append(pd.read_csv(file))\n",
    "# #             print(file)\n",
    "#         else:\n",
    "#             train_df_list.append(pd.read_csv(file))\n",
    "            \n",
    "\n",
    "#     print('Train Subject Trials: ',len(train_df_list))\n",
    "#     print('Test Subject Trials: ',len(test_df_list))\n",
    "    \n",
    "#     # Concatenate all DataFrames\n",
    "#     train_df   = pd.concat(train_df_list, ignore_index=True)\n",
    "#     test_df   = pd.concat(test_df_list, ignore_index=True)\n",
    "\n",
    "    \n",
    "#     lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "#     train_labels= train_df.pop('label')\n",
    "#     train_features = train_df\n",
    "\n",
    "#     test_labels= test_df.pop('label')\n",
    "#     test_features = test_df\n",
    "\n",
    "\n",
    "#     all_class_names = [\"G1\", 'G2', 'G3', 'G4', 'G5', 'G6', 'G8', 'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15']\n",
    "#     lb.fit(all_class_names)\n",
    "\n",
    "#     train_labels = lb.transform(train_labels)\n",
    "#     test_labels = lb.transform(test_labels)\n",
    "    \n",
    "#     train_x = train_features.to_numpy()\n",
    "#     train_y = train_labels\n",
    "\n",
    "#     test_x = test_features.to_numpy()\n",
    "#     test_y = test_labels\n",
    "\n",
    "#     seq_len = 30\n",
    "#     batch_size = 64\n",
    "\n",
    "#     valid_test_split = 0.8\n",
    "#     # Step 2: Split the remaining data into validation and test sets\n",
    "#     val_x, test_x, val_y, test_y = train_test_split(\n",
    "#     test_x, test_y, test_size=valid_test_split, random_state=42)\n",
    "    \n",
    "#     train_dataset = CustomDataset(train_x, train_y, seq_len, batch_size)\n",
    "    \n",
    "#     val_dataset = CustomDataset(val_x, val_y, seq_len, batch_size)\n",
    "    \n",
    "#     test_dataset = CustomDataset(test_x, test_y, seq_len, batch_size)\n",
    "\n",
    "#     train_dataloader = tf.data.Dataset.from_generator(\n",
    "#         lambda: train_dataset,\n",
    "#         output_signature=(\n",
    "#             tf.TensorSpec(shape=( seq_len, train_x.shape[1]), dtype=tf.float32),\n",
    "#             tf.TensorSpec(shape=( seq_len, train_y.shape[1]), dtype=tf.float32),\n",
    "#         ),\n",
    "#     # )\n",
    "#     ).repeat()\n",
    "#     train_dataloader = train_dataloader.batch(batch_size)\n",
    "\n",
    "\n",
    "#     val_dataloader = tf.data.Dataset.from_generator(\n",
    "#         lambda: val_dataset,\n",
    "#         output_signature=(\n",
    "#             tf.TensorSpec(shape=( seq_len, test_x.shape[1]), dtype=tf.float32),\n",
    "#             tf.TensorSpec(shape=( seq_len, test_y.shape[1]), dtype=tf.float32),\n",
    "#         ),\n",
    "#     )\n",
    "#     val_dataloader = val_dataloader.batch(batch_size)\n",
    "    \n",
    "\n",
    "#     test_dataloader = tf.data.Dataset.from_generator(\n",
    "#         lambda: test_dataset,\n",
    "#         output_signature=(\n",
    "#             tf.TensorSpec(shape=( seq_len, test_x.shape[1]), dtype=tf.float32),\n",
    "#             tf.TensorSpec(shape=( seq_len, test_y.shape[1]), dtype=tf.float32),\n",
    "#         ),\n",
    "#     )\n",
    "#     test_dataloader = test_dataloader.batch(batch_size)\n",
    "    \n",
    "#     return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in train_dataloader:\n",
    "#     print(item[0].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = 41 # -2 ## 43 -> G13 i.e 41 \n",
    "\n",
    "# print(lb.classes_)\n",
    "\n",
    "# print(lb.inverse_transform(test_labels)[row])\n",
    "# print(test_labels[row])\n",
    "\n",
    "# # print(train_labels.iloc[row])\n",
    "# # print(np.argmax(test_labels[row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "\n",
    "\n",
    "# all_class_names = [\"G1\", 'G2', 'G3', 'G4', 'G5', 'G6', 'G8', 'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15']\n",
    "\n",
    "# train_loader, test_loader = get_dataloaders(task=\"Knot_Tying\", subject_id_to_exclude=8, observation_window=30,prediction_window=30, batch_size=64, one_hot=True, class_names = all_class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        # self.embedding = tf.keras.layers.Embedding(input_size, d_model, mask_zero=True) \n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.linear(x)\n",
    "        length = tf.shape(x)[1]\n",
    "\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    \n",
    "\n",
    "        \n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    output_dim,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    \n",
    "    x = PositionalEmbedding(input_size=inputs.shape[1], d_model=head_size)(x)\n",
    "    \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "#     print(\"bf_glbl\",x.shape)\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\", keepdims=True)(x)\n",
    "#     print(\"af_glbl\",x.shape)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    print(output_dim)\n",
    "    outputs = layers.Dense(output_dim, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 12:22:59.973853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-28 12:22:59.974001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-28 12:22:59.974080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-28 12:22:59.974208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-28 12:22:59.974311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-28 12:22:59.974399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 32 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "input_dim:  (30, 66)\n",
      "output_dim:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 12:32:21.252823: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 512.0KiB (rounded to 524288)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-07-28 12:32:21.252889: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2023-07-28 12:32:21.252906: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 31, Chunks in use: 31. 7.8KiB allocated for chunks. 7.8KiB in use in bin. 245B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.252921: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-07-28 12:32:21.252932: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 67, Chunks in use: 67. 67.8KiB allocated for chunks. 67.8KiB in use in bin. 67.0KiB client-requested in use in bin.\n",
      "2023-07-28 12:32:21.252942: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 39, Chunks in use: 39. 81.0KiB allocated for chunks. 81.0KiB in use in bin. 78.0KiB client-requested in use in bin.\n",
      "2023-07-28 12:32:21.252950: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 7.0KiB allocated for chunks. 7.0KiB in use in bin. 7.0KiB client-requested in use in bin.\n",
      "2023-07-28 12:32:21.252959: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 8.5KiB allocated for chunks. 8.5KiB in use in bin. 7.0KiB client-requested in use in bin.\n",
      "2023-07-28 12:32:21.252968: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.252976: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.252986: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 2, Chunks in use: 2. 132.0KiB allocated for chunks. 132.0KiB in use in bin. 132.0KiB client-requested in use in bin.\n",
      "2023-07-28 12:32:21.252996: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 3, Chunks in use: 3. 508.0KiB allocated for chunks. 508.0KiB in use in bin. 322.0KiB client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253003: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253013: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 59, Chunks in use: 59. 29.89MiB allocated for chunks. 29.89MiB in use in bin. 29.50MiB client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253021: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253030: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 1. 2.00MiB allocated for chunks. 2.00MiB in use in bin. 2.00MiB client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253038: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253045: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253053: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253065: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253072: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253080: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253088: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-28 12:32:21.253099: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 512.0KiB was 512.0KiB, Chunk State: \n",
      "2023-07-28 12:32:21.253106: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 34275328\n",
      "2023-07-28 12:32:21.253121: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64000000 of size 1280 next 1\n",
      "2023-07-28 12:32:21.253128: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64000500 of size 256 next 2\n",
      "2023-07-28 12:32:21.253134: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64000600 of size 256 next 3\n",
      "2023-07-28 12:32:21.253141: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64000700 of size 256 next 4\n",
      "2023-07-28 12:32:21.253147: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64000800 of size 256 next 7\n",
      "2023-07-28 12:32:21.253153: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64000900 of size 256 next 8\n",
      "2023-07-28 12:32:21.253159: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64000a00 of size 256 next 10\n",
      "2023-07-28 12:32:21.253166: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64000b00 of size 1024 next 11\n",
      "2023-07-28 12:32:21.253173: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64000f00 of size 256 next 9\n",
      "2023-07-28 12:32:21.253180: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64001000 of size 1024 next 12\n",
      "2023-07-28 12:32:21.253186: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64001400 of size 1024 next 15\n",
      "2023-07-28 12:32:21.253192: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64001800 of size 256 next 16\n",
      "2023-07-28 12:32:21.253198: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64001900 of size 256 next 17\n",
      "2023-07-28 12:32:21.253205: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64001a00 of size 2048 next 20\n",
      "2023-07-28 12:32:21.253211: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64002200 of size 1024 next 74\n",
      "2023-07-28 12:32:21.253218: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64002600 of size 1024 next 104\n",
      "2023-07-28 12:32:21.253224: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64002a00 of size 2048 next 25\n",
      "2023-07-28 12:32:21.253230: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64003200 of size 256 next 18\n",
      "2023-07-28 12:32:21.253236: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64003300 of size 256 next 19\n",
      "2023-07-28 12:32:21.253242: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64003400 of size 1024 next 29\n",
      "2023-07-28 12:32:21.253249: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64003800 of size 1024 next 27\n",
      "2023-07-28 12:32:21.253255: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64003c00 of size 1024 next 28\n",
      "2023-07-28 12:32:21.253261: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64004000 of size 256 next 31\n",
      "2023-07-28 12:32:21.253268: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64004100 of size 256 next 32\n",
      "2023-07-28 12:32:21.253275: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64004200 of size 1024 next 33\n",
      "2023-07-28 12:32:21.253281: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64004600 of size 3072 next 35\n",
      "2023-07-28 12:32:21.253287: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64005200 of size 1024 next 38\n",
      "2023-07-28 12:32:21.253294: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64005600 of size 2048 next 39\n",
      "2023-07-28 12:32:21.253301: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64005e00 of size 1024 next 34\n",
      "2023-07-28 12:32:21.253307: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64006200 of size 1024 next 40\n",
      "2023-07-28 12:32:21.253312: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64006600 of size 2048 next 44\n",
      "2023-07-28 12:32:21.253318: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64006e00 of size 256 next 107\n",
      "2023-07-28 12:32:21.253324: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64006f00 of size 256 next 108\n",
      "2023-07-28 12:32:21.253330: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64007000 of size 1536 next 46\n",
      "2023-07-28 12:32:21.253337: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64007600 of size 1024 next 48\n",
      "2023-07-28 12:32:21.253343: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64007a00 of size 1024 next 110\n",
      "2023-07-28 12:32:21.253349: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64007e00 of size 1024 next 49\n",
      "2023-07-28 12:32:21.253355: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64008200 of size 1024 next 50\n",
      "2023-07-28 12:32:21.253360: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64008600 of size 1024 next 52\n",
      "2023-07-28 12:32:21.253366: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64008a00 of size 1024 next 54\n",
      "2023-07-28 12:32:21.253372: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64008e00 of size 2048 next 55\n",
      "2023-07-28 12:32:21.253378: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64009600 of size 2048 next 56\n",
      "2023-07-28 12:32:21.253383: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64009e00 of size 1024 next 58\n",
      "2023-07-28 12:32:21.253389: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400a200 of size 3072 next 62\n",
      "2023-07-28 12:32:21.253395: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400ae00 of size 1024 next 64\n",
      "2023-07-28 12:32:21.253400: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400b200 of size 1024 next 60\n",
      "2023-07-28 12:32:21.253406: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400b600 of size 1024 next 65\n",
      "2023-07-28 12:32:21.253412: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400ba00 of size 1024 next 66\n",
      "2023-07-28 12:32:21.253417: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400be00 of size 2048 next 70\n",
      "2023-07-28 12:32:21.253423: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400c600 of size 2048 next 71\n",
      "2023-07-28 12:32:21.253429: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400ce00 of size 1024 next 68\n",
      "2023-07-28 12:32:21.253434: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400d200 of size 1024 next 72\n",
      "2023-07-28 12:32:21.253440: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400d600 of size 2048 next 76\n",
      "2023-07-28 12:32:21.253446: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400de00 of size 2048 next 78\n",
      "2023-07-28 12:32:21.253452: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400e600 of size 1024 next 80\n",
      "2023-07-28 12:32:21.253459: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400ea00 of size 2048 next 81\n",
      "2023-07-28 12:32:21.253464: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400f200 of size 1024 next 82\n",
      "2023-07-28 12:32:21.253470: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400f600 of size 256 next 84\n",
      "2023-07-28 12:32:21.253476: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400f700 of size 256 next 86\n",
      "2023-07-28 12:32:21.253482: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400f800 of size 1024 next 88\n",
      "2023-07-28 12:32:21.253487: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400fc00 of size 256 next 89\n",
      "2023-07-28 12:32:21.253493: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400fd00 of size 256 next 87\n",
      "2023-07-28 12:32:21.253499: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400fe00 of size 256 next 96\n",
      "2023-07-28 12:32:21.253504: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6400ff00 of size 256 next 94\n",
      "2023-07-28 12:32:21.253510: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010000 of size 256 next 90\n",
      "2023-07-28 12:32:21.253516: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010100 of size 256 next 93\n",
      "2023-07-28 12:32:21.253521: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010200 of size 256 next 91\n",
      "2023-07-28 12:32:21.253527: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010300 of size 512 next 85\n",
      "2023-07-28 12:32:21.253533: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010500 of size 256 next 42\n",
      "2023-07-28 12:32:21.253539: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010600 of size 256 next 92\n",
      "2023-07-28 12:32:21.253544: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010700 of size 256 next 97\n",
      "2023-07-28 12:32:21.253550: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010800 of size 256 next 98\n",
      "2023-07-28 12:32:21.253555: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010900 of size 256 next 99\n",
      "2023-07-28 12:32:21.253561: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010a00 of size 256 next 102\n",
      "2023-07-28 12:32:21.253567: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010b00 of size 1024 next 103\n",
      "2023-07-28 12:32:21.253573: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64010f00 of size 2048 next 13\n",
      "2023-07-28 12:32:21.253578: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64011700 of size 2048 next 14\n",
      "2023-07-28 12:32:21.253584: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64011f00 of size 8704 next 100\n",
      "2023-07-28 12:32:21.253590: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64014100 of size 2048 next 106\n",
      "2023-07-28 12:32:21.253596: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64014900 of size 2048 next 111\n",
      "2023-07-28 12:32:21.253601: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64015100 of size 3072 next 101\n",
      "2023-07-28 12:32:21.253608: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64015d00 of size 131072 next 23\n",
      "2023-07-28 12:32:21.253615: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64035d00 of size 67584 next 109\n",
      "2023-07-28 12:32:21.253621: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64046500 of size 2048 next 114\n",
      "2023-07-28 12:32:21.253627: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64046d00 of size 1024 next 116\n",
      "2023-07-28 12:32:21.253632: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64047100 of size 1024 next 117\n",
      "2023-07-28 12:32:21.253638: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64047500 of size 1024 next 118\n",
      "2023-07-28 12:32:21.253645: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64047900 of size 2048 next 120\n",
      "2023-07-28 12:32:21.253651: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64048100 of size 1024 next 122\n",
      "2023-07-28 12:32:21.253656: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64048500 of size 1024 next 123\n",
      "2023-07-28 12:32:21.253662: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64048900 of size 1024 next 124\n",
      "2023-07-28 12:32:21.253668: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64048d00 of size 2048 next 126\n",
      "2023-07-28 12:32:21.253674: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64049500 of size 2048 next 128\n",
      "2023-07-28 12:32:21.253679: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64049d00 of size 2048 next 130\n",
      "2023-07-28 12:32:21.253685: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404a500 of size 1024 next 132\n",
      "2023-07-28 12:32:21.253691: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404a900 of size 1024 next 133\n",
      "2023-07-28 12:32:21.253696: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404ad00 of size 1024 next 134\n",
      "2023-07-28 12:32:21.253702: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404b100 of size 2048 next 136\n",
      "2023-07-28 12:32:21.253708: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404b900 of size 1024 next 138\n",
      "2023-07-28 12:32:21.253713: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404bd00 of size 1024 next 139\n",
      "2023-07-28 12:32:21.253719: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404c100 of size 1024 next 140\n",
      "2023-07-28 12:32:21.253725: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404c500 of size 2048 next 142\n",
      "2023-07-28 12:32:21.253731: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404cd00 of size 2048 next 144\n",
      "2023-07-28 12:32:21.253736: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404d500 of size 2048 next 146\n",
      "2023-07-28 12:32:21.253742: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404dd00 of size 1024 next 148\n",
      "2023-07-28 12:32:21.253748: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404e100 of size 1024 next 149\n",
      "2023-07-28 12:32:21.253753: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404e500 of size 1024 next 150\n",
      "2023-07-28 12:32:21.253759: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404e900 of size 2048 next 152\n",
      "2023-07-28 12:32:21.253765: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404f100 of size 1024 next 154\n",
      "2023-07-28 12:32:21.253770: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404f500 of size 1024 next 155\n",
      "2023-07-28 12:32:21.253776: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404f900 of size 1024 next 156\n",
      "2023-07-28 12:32:21.253782: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e6404fd00 of size 2048 next 158\n",
      "2023-07-28 12:32:21.253787: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64050500 of size 2048 next 160\n",
      "2023-07-28 12:32:21.253793: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64050d00 of size 2048 next 162\n",
      "2023-07-28 12:32:21.253799: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64051500 of size 1024 next 164\n",
      "2023-07-28 12:32:21.253805: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64051900 of size 1024 next 165\n",
      "2023-07-28 12:32:21.253811: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64051d00 of size 1024 next 166\n",
      "2023-07-28 12:32:21.253816: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64052100 of size 2048 next 168\n",
      "2023-07-28 12:32:21.253822: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64052900 of size 1024 next 170\n",
      "2023-07-28 12:32:21.253829: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64052d00 of size 1024 next 171\n",
      "2023-07-28 12:32:21.253835: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64053100 of size 1024 next 172\n",
      "2023-07-28 12:32:21.253841: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64053500 of size 258048 next 95\n",
      "2023-07-28 12:32:21.253847: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64092500 of size 131072 next 36\n",
      "2023-07-28 12:32:21.253853: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e640b2500 of size 524288 next 22\n",
      "2023-07-28 12:32:21.253859: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64132500 of size 524288 next 21\n",
      "2023-07-28 12:32:21.253865: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e641b2500 of size 524288 next 24\n",
      "2023-07-28 12:32:21.253870: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64232500 of size 524288 next 26\n",
      "2023-07-28 12:32:21.253876: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e642b2500 of size 524288 next 30\n",
      "2023-07-28 12:32:21.253882: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64332500 of size 844544 next 5\n",
      "2023-07-28 12:32:21.253888: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64400800 of size 2097152 next 6\n",
      "2023-07-28 12:32:21.253895: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64600800 of size 524288 next 37\n",
      "2023-07-28 12:32:21.253901: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64680800 of size 524288 next 41\n",
      "2023-07-28 12:32:21.253907: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64700800 of size 524288 next 43\n",
      "2023-07-28 12:32:21.253913: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64780800 of size 524288 next 45\n",
      "2023-07-28 12:32:21.253919: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64800800 of size 524288 next 47\n",
      "2023-07-28 12:32:21.253924: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64880800 of size 524288 next 51\n",
      "2023-07-28 12:32:21.253930: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64900800 of size 524288 next 53\n",
      "2023-07-28 12:32:21.253936: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64980800 of size 524288 next 57\n",
      "2023-07-28 12:32:21.253941: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64a00800 of size 524288 next 59\n",
      "2023-07-28 12:32:21.253947: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64a80800 of size 524288 next 61\n",
      "2023-07-28 12:32:21.253953: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64b00800 of size 524288 next 63\n",
      "2023-07-28 12:32:21.253958: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64b80800 of size 524288 next 67\n",
      "2023-07-28 12:32:21.253964: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64c00800 of size 524288 next 69\n",
      "2023-07-28 12:32:21.253971: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64c80800 of size 524288 next 73\n",
      "2023-07-28 12:32:21.253977: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64d00800 of size 524288 next 75\n",
      "2023-07-28 12:32:21.253983: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64d80800 of size 524288 next 77\n",
      "2023-07-28 12:32:21.253989: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64e00800 of size 524288 next 79\n",
      "2023-07-28 12:32:21.253995: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64e80800 of size 524288 next 83\n",
      "2023-07-28 12:32:21.254001: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64f00800 of size 524288 next 105\n",
      "2023-07-28 12:32:21.254008: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e64f80800 of size 524288 next 112\n",
      "2023-07-28 12:32:21.254015: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65000800 of size 524288 next 113\n",
      "2023-07-28 12:32:21.254021: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65080800 of size 524288 next 115\n",
      "2023-07-28 12:32:21.254027: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65100800 of size 524288 next 119\n",
      "2023-07-28 12:32:21.254034: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65180800 of size 524288 next 121\n",
      "2023-07-28 12:32:21.254040: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65200800 of size 524288 next 125\n",
      "2023-07-28 12:32:21.254046: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65280800 of size 524288 next 127\n",
      "2023-07-28 12:32:21.254052: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65300800 of size 524288 next 129\n",
      "2023-07-28 12:32:21.254058: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65380800 of size 524288 next 131\n",
      "2023-07-28 12:32:21.254064: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65400800 of size 524288 next 135\n",
      "2023-07-28 12:32:21.254070: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65480800 of size 524288 next 137\n",
      "2023-07-28 12:32:21.254076: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65500800 of size 524288 next 141\n",
      "2023-07-28 12:32:21.254083: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65580800 of size 524288 next 143\n",
      "2023-07-28 12:32:21.254089: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65600800 of size 524288 next 145\n",
      "2023-07-28 12:32:21.254095: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65680800 of size 524288 next 147\n",
      "2023-07-28 12:32:21.254101: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65700800 of size 524288 next 151\n",
      "2023-07-28 12:32:21.254107: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65780800 of size 524288 next 153\n",
      "2023-07-28 12:32:21.254113: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65800800 of size 524288 next 157\n",
      "2023-07-28 12:32:21.254119: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65880800 of size 524288 next 159\n",
      "2023-07-28 12:32:21.254126: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65900800 of size 524288 next 161\n",
      "2023-07-28 12:32:21.254132: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65980800 of size 524288 next 163\n",
      "2023-07-28 12:32:21.254138: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65a00800 of size 524288 next 167\n",
      "2023-07-28 12:32:21.254144: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65a80800 of size 524288 next 169\n",
      "2023-07-28 12:32:21.254150: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b00800 of size 512 next 173\n",
      "2023-07-28 12:32:21.254157: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b00a00 of size 7168 next 174\n",
      "2023-07-28 12:32:21.254163: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b02600 of size 256 next 175\n",
      "2023-07-28 12:32:21.254170: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b02700 of size 67584 next 176\n",
      "2023-07-28 12:32:21.254176: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b12f00 of size 1024 next 177\n",
      "2023-07-28 12:32:21.254183: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b13300 of size 1024 next 178\n",
      "2023-07-28 12:32:21.254189: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b13700 of size 1024 next 179\n",
      "2023-07-28 12:32:21.254195: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b13b00 of size 524288 next 180\n",
      "2023-07-28 12:32:21.254202: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b93b00 of size 2048 next 181\n",
      "2023-07-28 12:32:21.254209: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65b94300 of size 524288 next 182\n",
      "2023-07-28 12:32:21.254216: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65c14300 of size 2048 next 183\n",
      "2023-07-28 12:32:21.254222: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65c14b00 of size 524288 next 184\n",
      "2023-07-28 12:32:21.254228: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65c94b00 of size 2048 next 185\n",
      "2023-07-28 12:32:21.254235: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65c95300 of size 524288 next 186\n",
      "2023-07-28 12:32:21.254241: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65d15300 of size 1024 next 187\n",
      "2023-07-28 12:32:21.254247: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65d15700 of size 1024 next 188\n",
      "2023-07-28 12:32:21.254253: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65d15b00 of size 1024 next 189\n",
      "2023-07-28 12:32:21.254259: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65d15f00 of size 524288 next 190\n",
      "2023-07-28 12:32:21.254266: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65d95f00 of size 2048 next 191\n",
      "2023-07-28 12:32:21.254272: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65d96700 of size 524288 next 192\n",
      "2023-07-28 12:32:21.254278: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65e16700 of size 1024 next 193\n",
      "2023-07-28 12:32:21.254284: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65e16b00 of size 1024 next 194\n",
      "2023-07-28 12:32:21.254291: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65e16f00 of size 1024 next 195\n",
      "2023-07-28 12:32:21.254297: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65e17300 of size 524288 next 196\n",
      "2023-07-28 12:32:21.254303: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65e97300 of size 2048 next 197\n",
      "2023-07-28 12:32:21.254309: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65e97b00 of size 524288 next 198\n",
      "2023-07-28 12:32:21.254316: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65f17b00 of size 2048 next 199\n",
      "2023-07-28 12:32:21.254322: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65f18300 of size 524288 next 200\n",
      "2023-07-28 12:32:21.254328: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65f98300 of size 2048 next 201\n",
      "2023-07-28 12:32:21.254334: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e65f98b00 of size 524288 next 202\n",
      "2023-07-28 12:32:21.254341: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e66018b00 of size 1024 next 203\n",
      "2023-07-28 12:32:21.254347: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e66018f00 of size 1024 next 204\n",
      "2023-07-28 12:32:21.254353: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e66019300 of size 1024 next 205\n",
      "2023-07-28 12:32:21.254360: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f3e66019700 of size 616704 next 18446744073709551615\n",
      "2023-07-28 12:32:21.254366: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2023-07-28 12:32:21.254376: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 31 Chunks of size 256 totalling 7.8KiB\n",
      "2023-07-28 12:32:21.254383: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2023-07-28 12:32:21.254391: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 65 Chunks of size 1024 totalling 65.0KiB\n",
      "2023-07-28 12:32:21.254398: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-07-28 12:32:21.254405: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1536 totalling 1.5KiB\n",
      "2023-07-28 12:32:21.254413: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 36 Chunks of size 2048 totalling 72.0KiB\n",
      "2023-07-28 12:32:21.254421: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 3072 totalling 9.0KiB\n",
      "2023-07-28 12:32:21.254427: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 7168 totalling 7.0KiB\n",
      "2023-07-28 12:32:21.254435: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 8704 totalling 8.5KiB\n",
      "2023-07-28 12:32:21.254442: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 67584 totalling 132.0KiB\n",
      "2023-07-28 12:32:21.254449: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 131072 totalling 256.0KiB\n",
      "2023-07-28 12:32:21.254456: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 258048 totalling 252.0KiB\n",
      "2023-07-28 12:32:21.254464: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 57 Chunks of size 524288 totalling 28.50MiB\n",
      "2023-07-28 12:32:21.254471: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 616704 totalling 602.2KiB\n",
      "2023-07-28 12:32:21.254478: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 844544 totalling 824.8KiB\n",
      "2023-07-28 12:32:21.254485: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 2097152 totalling 2.00MiB\n",
      "2023-07-28 12:32:21.254493: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 32.69MiB\n",
      "2023-07-28 12:32:21.254500: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 34275328 memory_limit_: 34275328 available bytes: 0 curr_region_allocation_bytes_: 68550656\n",
      "2023-07-28 12:32:21.254514: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                        34275328\n",
      "InUse:                        34275328\n",
      "MaxInUse:                     34275328\n",
      "NumAllocs:                         491\n",
      "MaxAllocSize:                  4194304\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-07-28 12:32:21.254532: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ****************************************************************************************************\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minput_dim: \u001b[39m\u001b[39m\"\u001b[39m,input_shape)\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39moutput_dim: \u001b[39m\u001b[39m\"\u001b[39m,output_dim)\n\u001b[0;32m---> 19\u001b[0m model \u001b[39m=\u001b[39m build_model(\n\u001b[1;32m     20\u001b[0m     input_shape,\n\u001b[1;32m     21\u001b[0m     output_dim,\n\u001b[1;32m     22\u001b[0m     head_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     23\u001b[0m     num_heads\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     24\u001b[0m     ff_dim\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m     25\u001b[0m     num_transformer_blocks\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     26\u001b[0m     mlp_units\u001b[39m=\u001b[39;49m[\u001b[39m256\u001b[39;49m,\u001b[39m128\u001b[39;49m],\n\u001b[1;32m     27\u001b[0m     mlp_dropout\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     28\u001b[0m     dropout\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     32\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m),\n\u001b[1;32m     34\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcategorical_accuracy\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[39m# # # # model.summary()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(input_shape, output_dim, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)\u001b[0m\n\u001b[1;32m     12\u001b[0m inputs \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minput_shape)\n\u001b[1;32m     13\u001b[0m x \u001b[39m=\u001b[39m inputs\n\u001b[0;32m---> 15\u001b[0m x \u001b[39m=\u001b[39m PositionalEmbedding(input_size\u001b[39m=\u001b[39;49minputs\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], d_model\u001b[39m=\u001b[39;49mhead_size)(x)\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_transformer_blocks):\n\u001b[1;32m     18\u001b[0m     x \u001b[39m=\u001b[39m transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m, in \u001b[0;36mPositionalEmbedding.__init__\u001b[0;34m(self, input_size, d_model)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model \u001b[39m=\u001b[39m d_model\n\u001b[1;32m      5\u001b[0m \u001b[39m# self.embedding = tf.keras.layers.Embedding(input_size, d_model, mask_zero=True) \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoding \u001b[39m=\u001b[39m positional_encoding(length\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m, depth\u001b[39m=\u001b[39;49md_model)\n\u001b[1;32m      7\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(d_model)\n",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m, in \u001b[0;36mpositional_encoding\u001b[0;34m(length, depth)\u001b[0m\n\u001b[1;32m      8\u001b[0m angle_rads \u001b[39m=\u001b[39m positions \u001b[39m*\u001b[39m angle_rates      \u001b[39m# (pos, depth)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m pos_encoding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(\n\u001b[1;32m     11\u001b[0m   [np\u001b[39m.\u001b[39msin(angle_rads), np\u001b[39m.\u001b[39mcos(angle_rads)],\n\u001b[1;32m     12\u001b[0m   axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[0;32m---> 14\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcast(pos_encoding, dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat32)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# input_shape = (30,66)\n",
    "# input_shape = train_features.shape\n",
    "\n",
    "# train_features = train_features.to_numpy()\n",
    "# train_features = train_features.reshape((train_features.shape[0], train_features.shape[1], 1))\n",
    "# input_shape = train_features.shape\n",
    "subject = \"S04\"\n",
    "train_dataloader, test_dataloader = generate_data_split(subject)\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "input_shape = train_features.shape[1:]\n",
    "output_dim = train_labels.shape[2]\n",
    "\n",
    "print(\"input_dim: \",input_shape)\n",
    "print(\"output_dim: \",output_dim)\n",
    "\n",
    "\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    output_dim,\n",
    "    head_size=32,\n",
    "    num_heads=2,\n",
    "    ff_dim=64,\n",
    "    num_transformer_blocks=2,\n",
    "    mlp_units=[256,128],\n",
    "    mlp_dropout=0.2,\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")\n",
    "# # # # model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)]\n",
    "\n",
    "epochs = 100\n",
    "# steps_per_epoch = train_dataloader.__len__()//1\n",
    "# print(\"steps_per\", steps_per_epoch)\n",
    "\n",
    "\n",
    "subjects = ['S02','S03','S04','S05','S06','S07','S08','S09']\n",
    "\n",
    "\n",
    "model.save_weights('./checkpoints/blank_state')\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    print(\" *** --------START TRAIN--------- *** \")\n",
    "    print(\"SUBJECT EXCLUDED: \",subject)\n",
    "    \n",
    "    train_dataloader, test_dataloader = generate_data_split(subject)\n",
    "\n",
    "    model.load_weights('./checkpoints/blank_state')\n",
    "\n",
    "    model.fit(\n",
    "        train_dataloader,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=500,\n",
    "#         validation_data = valid_dataloader\n",
    "    )\n",
    "\n",
    "    print(\" *** -------END TRAIN-------- *** \")\n",
    "    print(\" *** -------START EVAL-------- *** \")\n",
    "    \n",
    "    model.evaluate(test_dataloader, verbose=1)\n",
    "\n",
    "    print(\" *** -------END EVAL-------- *** \")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "## Pytorch dataloader implementation\n",
    "\n",
    "# def gen(torch_loader):\n",
    "#     for x,y in torch_loader:\n",
    "#         yield (x,y)\n",
    "\n",
    "# train = gen(train_dataloader)\n",
    "\n",
    "# epochs = 300\n",
    "# steps_per_epoch = train_dataloader.__len__()//5\n",
    "# print(\"steps_per\", steps_per_epoch)\n",
    "\n",
    "# model.fit(\n",
    "#     train,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=callbacks,\n",
    "#     steps_per_epoch=steps_per_epoch\n",
    "# )\n",
    "\n",
    "# # model.evaluate(x_test, y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S02\n",
      "Train Subject Trials:  32\n",
      "Test Subject Trials:  4\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0771 - categorical_accuracy: 0.9830\n",
      " *** --------END--------- *** \n",
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S03\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0755 - categorical_accuracy: 0.9796\n",
      " *** --------END--------- *** \n",
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S04\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0591 - categorical_accuracy: 0.9806\n",
      " *** --------END--------- *** \n",
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S05\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0815 - categorical_accuracy: 0.9772\n",
      " *** --------END--------- *** \n",
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S06\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0427 - categorical_accuracy: 0.9871\n",
      " *** --------END--------- *** \n",
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S07\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0652 - categorical_accuracy: 0.9856\n",
      " *** --------END--------- *** \n",
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S08\n",
      "Train Subject Trials:  33\n",
      "Test Subject Trials:  3\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0523 - categorical_accuracy: 0.9901\n",
      " *** --------END--------- *** \n",
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S09\n",
      "Train Subject Trials:  32\n",
      "Test Subject Trials:  4\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2410 - categorical_accuracy: 0.9495\n",
      " *** --------END--------- *** \n"
     ]
    }
   ],
   "source": [
    "subjects = ['S02','S03','S04','S05','S06','S07','S08','S09']\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    print(\" *** --------START--------- *** \")\n",
    "    print(\"SUBJECT EXCLUDED: \",subject)\n",
    "    \n",
    "    train_dataloader, test_dataloader = generate_data_split(subject)\n",
    "    model.evaluate(test_dataloader, verbose=1)\n",
    "    \n",
    "\n",
    "    print(\" *** --------END--------- *** \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras_tuner as kt\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "# input_shape = train_features.shape[1:]\n",
    "# output_dim = train_labels.shape[2]\n",
    "\n",
    "# print(\"input_dim: \",input_shape)\n",
    "# print(\"output_dim: \",output_dim)\n",
    "\n",
    "\n",
    "# def model_builder(hp):\n",
    "    \n",
    "    \n",
    "#     hp_headsize = hp.Int('units', min_value=16, max_value=512, step=16)\n",
    "#     hp_numheads = hp.Int('units', min_value=2, max_value=16, step=2)\n",
    "#     hp_ff_dim = hp.Int('units', min_value=1, max_value=512, step=16)\n",
    "#     hp_num_transformer_blocks = hp.Int('units', min_value=1, max_value=16, step=2)\n",
    "\n",
    "#     model = build_model(\n",
    "#     input_shape,\n",
    "#     output_dim,\n",
    "#     head_size=hp_headsize,\n",
    "#     num_heads=hp_numheads,\n",
    "#     ff_dim=hp_ff_dim,\n",
    "#     num_transformer_blocks=hp_num_transformer_blocks,\n",
    "#     mlp_units=[128],\n",
    "#     mlp_dropout=0.4,\n",
    "#     dropout=0.25,\n",
    "#     )\n",
    "\n",
    "#     model.compile(\n",
    "#         loss=\"categorical_crossentropy\",\n",
    "#         optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#         metrics=[\"categorical_accuracy\"],\n",
    "#     )\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# tuner = kt.Hyperband(model_builder,\n",
    "#                      objective='val_accuracy',\n",
    "#                      max_epochs=10,\n",
    "#                      factor=3,\n",
    "#                      project_name='intro_to_kt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search(train_dataloader, epochs=10, steps_per_epoch=500, callbacks=[stop_early])\n",
    "\n",
    "# # Get the optimal hyperparameters\n",
    "# best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "# layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "# is {best_hps.get('learning_rate')}.\n",
    "# \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataloader, verbose=1)\n",
    "\n",
    "# test_features, test_labels = next(iter(test_dataloader))\n",
    "\n",
    "# y_pred = model(test_features)\n",
    "\n",
    "# relu = nn.ReLU()\n",
    "\n",
    "\n",
    "# for idx,y in enumerate(y_pred) :\n",
    "#     for i,sample in enumerate(y):\n",
    "#         print(np.argmax(test_labels[idx][i].numpy()))\n",
    "#         print(np.argmax(sample))\n",
    "#         print('-----')\n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/progress_v4_07_27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restore the weights\n",
    "# model.load_weights('./checkpoints/progress_v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsurgery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
