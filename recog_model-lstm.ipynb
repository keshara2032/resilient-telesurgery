{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/kesharaw/anaconda3/envs/tensorflow/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/kesharaw/anaconda3/envs/tensorflow/lib/python3.8/site-packages (from pydot) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import glob\n",
    "\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Subject Trials:  32\n",
      "Test Subject Trials:  4\n",
      "input_dim:  (30, 66)\n",
      "output_dim:  14\n"
     ]
    }
   ],
   "source": [
    "## generate test / train split\n",
    "\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, seq_len, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.seq_len)))\n",
    "\n",
    "        \n",
    "    def most_common(self,lst):\n",
    "        # print(\"mc\",lst)\n",
    "        lst = [np.where(r==1)[0][0] for r in lst]\n",
    "        return (np.bincount(lst).argmax())\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.seq_len\n",
    "        end_idx = (idx + 1) * self.seq_len\n",
    "\n",
    "        batch_x = self.x[start_idx:end_idx]\n",
    "        batch_y = self.y[start_idx:end_idx]\n",
    "        \n",
    "        \n",
    "        # most_com = self.most_common(batch_y)\n",
    "        # print(most_com)\n",
    "        \n",
    "        batch_x = torch.from_numpy(batch_x)\n",
    "        batch_y = torch.from_numpy(batch_y)\n",
    "        \n",
    "        # Pad sequences to ensure they have the same length within the batch\n",
    "        pad_len = self.seq_len - batch_x.shape[0]\n",
    "        if pad_len > 0:\n",
    "            pad_shape = (pad_len,) + batch_x.shape[1:]\n",
    "            pad_shape_y = (pad_len,) + batch_y.shape[1:]\n",
    "            \n",
    "            batch_x = torch.cat([batch_x, torch.zeros(pad_shape)], dim=0)\n",
    "            batch_y = torch.cat([batch_y, torch.zeros(pad_shape_y)], dim=0)\n",
    "\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        indices = np.arange(len(self.x))\n",
    "        np.random.shuffle(indices)\n",
    "        self.x = self.x[indices]\n",
    "        self.y = self.y[indices]\n",
    "        \n",
    "def generate_data_split(subject_id):\n",
    "    # Get CSV files list from a folder\n",
    "    train_path = './Train'\n",
    "    test_path = './Test'\n",
    "    \n",
    "    csv_path = './ProcessedDatasets/Knot_Tying'\n",
    "    \n",
    "    csv_files = glob.glob(csv_path + \"/*.csv\")\n",
    "    \n",
    "    train_df_list = []\n",
    "    test_df_list = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        if(subject_id in file):\n",
    "            test_df_list.append(pd.read_csv(file))\n",
    "#             print(file)\n",
    "        else:\n",
    "            train_df_list.append(pd.read_csv(file))\n",
    "            \n",
    "\n",
    "    print('Train Subject Trials: ',len(train_df_list))\n",
    "    print('Test Subject Trials: ',len(test_df_list))\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    train_df   = pd.concat(train_df_list, ignore_index=True)\n",
    "    test_df   = pd.concat(test_df_list, ignore_index=True)\n",
    "\n",
    "    \n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "    train_labels= train_df.pop('label')\n",
    "    train_features = train_df\n",
    "\n",
    "    test_labels= test_df.pop('label')\n",
    "    test_features = test_df\n",
    "\n",
    "\n",
    "    all_class_names = [\"G1\", 'G2', 'G3', 'G4', 'G5', 'G6', 'G8', 'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15']\n",
    "    lb.fit(all_class_names)\n",
    "\n",
    "    train_labels = lb.transform(train_labels)\n",
    "    test_labels = lb.transform(test_labels)\n",
    "    \n",
    "    train_x = train_features.to_numpy()\n",
    "    train_y = train_labels\n",
    "\n",
    "    test_x = test_features.to_numpy()\n",
    "    test_y = test_labels\n",
    "\n",
    "    seq_len = 30\n",
    "    batch_size = 64\n",
    "\n",
    "    valid_test_split = 0.8\n",
    "    # Step 2: Split the remaining data into validation and test sets\n",
    "    val_x, test_x, val_y, test_y = train_test_split(\n",
    "    test_x, test_y, test_size=valid_test_split, random_state=42)\n",
    "    \n",
    "    train_dataset = CustomDataset(train_x, train_y, seq_len, batch_size)\n",
    "    \n",
    "    val_dataset = CustomDataset(val_x, val_y, seq_len, batch_size)\n",
    "    \n",
    "    test_dataset = CustomDataset(test_x, test_y, seq_len, batch_size)\n",
    "\n",
    "    train_dataloader = tf.data.Dataset.from_generator(\n",
    "        lambda: train_dataset,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=( seq_len, train_x.shape[1]), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=( seq_len, train_y.shape[1]), dtype=tf.float32),\n",
    "        ),\n",
    "    # )\n",
    "    ).repeat()\n",
    "    train_dataloader = train_dataloader.batch(batch_size)\n",
    "\n",
    "\n",
    "    val_dataloader = tf.data.Dataset.from_generator(\n",
    "        lambda: val_dataset,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=( seq_len, test_x.shape[1]), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=( seq_len, test_y.shape[1]), dtype=tf.float32),\n",
    "        ),\n",
    "    )\n",
    "    val_dataloader = val_dataloader.batch(batch_size)\n",
    "    \n",
    "\n",
    "    test_dataloader = tf.data.Dataset.from_generator(\n",
    "        lambda: test_dataset,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=( seq_len, test_x.shape[1]), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=( seq_len, test_y.shape[1]), dtype=tf.float32),\n",
    "        ),\n",
    "    )\n",
    "    test_dataloader = test_dataloader.batch(batch_size)\n",
    "    \n",
    "    return train_dataloader, val_dataloader, test_dataloader\n",
    "    \n",
    "subjects = ['S02','S03','S04','S05','S06','S07','S08','S09']\n",
    "\n",
    "for subject in subjects:\n",
    "    train_dataloader, val_dataloader, test_dataloader = generate_data_split(subject)\n",
    "    train_features, train_labels = next(iter(val_dataloader))\n",
    "\n",
    "    input_shape = train_features.shape[1:]\n",
    "    output_dim = train_labels.shape[2]\n",
    "\n",
    "    print(\"input_dim: \",input_shape)\n",
    "    print(\"output_dim: \",output_dim)\n",
    "    \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "input_dim:  (30, 66)\n",
      "output_dim:  14\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\", keepdims=True)(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = generate_data_split('S04')\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "input_shape = train_features.shape[1:]\n",
    "output_dim = train_labels.shape[2]\n",
    "\n",
    "print(\"input_dim: \",input_shape)\n",
    "print(\"output_dim: \",output_dim)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=input_shape, num_classes=output_dim)\n",
    "# keras.utils.plot_model(model, show_shapes=True)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** --------START TRAIN--------- *** \n",
      "SUBJECT EXCLUDED:  S02\n",
      "Train Subject Trials:  32\n",
      "Test Subject Trials:  4\n",
      "Epoch 1/25\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.3120 - categorical_accuracy: 0.3560 - val_loss: 2.3067 - val_categorical_accuracy: 0.2967 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.7627 - categorical_accuracy: 0.4354 - val_loss: 2.0141 - val_categorical_accuracy: 0.2917 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 1.4633 - categorical_accuracy: 0.4270 - val_loss: 2.0656 - val_categorical_accuracy: 0.3192 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 1.2730 - categorical_accuracy: 0.6045 - val_loss: 3.4797 - val_categorical_accuracy: 0.3083 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 1.1476 - categorical_accuracy: 0.6559 - val_loss: 2.0313 - val_categorical_accuracy: 0.1117 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 1.0666 - categorical_accuracy: 0.6724 - val_loss: 2.1068 - val_categorical_accuracy: 0.1158 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 0.9919 - categorical_accuracy: 0.6911 - val_loss: 2.2612 - val_categorical_accuracy: 0.1075 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.9227 - categorical_accuracy: 0.7110 - val_loss: 2.3291 - val_categorical_accuracy: 0.2783 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.8811 - categorical_accuracy: 0.7165 - val_loss: 2.4815 - val_categorical_accuracy: 0.1958 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.8445 - categorical_accuracy: 0.7214 - val_loss: 2.4743 - val_categorical_accuracy: 0.1308 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.8193 - categorical_accuracy: 0.7240 - val_loss: 3.8647 - val_categorical_accuracy: 0.2575 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.7933 - categorical_accuracy: 0.7301 - val_loss: 2.7862 - val_categorical_accuracy: 0.2283 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.7676 - categorical_accuracy: 0.7348 - val_loss: 5.8557 - val_categorical_accuracy: 0.3433 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.7926 - categorical_accuracy: 0.7239 - val_loss: 2.6589 - val_categorical_accuracy: 0.1458 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.7204 - categorical_accuracy: 0.7456 - val_loss: 2.6307 - val_categorical_accuracy: 0.1658 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.7086 - categorical_accuracy: 0.7465 - val_loss: 3.0374 - val_categorical_accuracy: 0.1367 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.7014 - categorical_accuracy: 0.7447 - val_loss: 10.1291 - val_categorical_accuracy: 0.3267 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.6791 - categorical_accuracy: 0.7517 - val_loss: 3.2144 - val_categorical_accuracy: 0.2258 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.7306 - categorical_accuracy: 0.7341 - val_loss: 2.9883 - val_categorical_accuracy: 0.2683 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.6774 - categorical_accuracy: 0.7483 - val_loss: 4.2042 - val_categorical_accuracy: 0.2992 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.6403 - categorical_accuracy: 0.7589 - val_loss: 3.4367 - val_categorical_accuracy: 0.1833 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.7090 - categorical_accuracy: 0.7399 - val_loss: 4.7328 - val_categorical_accuracy: 0.2475 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.6750 - categorical_accuracy: 0.7443 - val_loss: 5.3221 - val_categorical_accuracy: 0.2742 - lr: 5.0000e-04\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.6314 - categorical_accuracy: 0.7584 - val_loss: 5.4398 - val_categorical_accuracy: 0.3017 - lr: 5.0000e-04\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 0.6195 - categorical_accuracy: 0.7619 - val_loss: 8.8735 - val_categorical_accuracy: 0.3358 - lr: 5.0000e-04\n",
      " *** -------END TRAIN-------- *** \n",
      " *** -------START EVAL-------- *** \n",
      "3/3 [==============================] - 0s 17ms/step - loss: 8.6851 - categorical_accuracy: 0.3280\n",
      " *** -------END EVAL-------- *** \n",
      " *** --------START TRAIN--------- *** \n",
      "SUBJECT EXCLUDED:  S03\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "Epoch 1/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 2.2819 - categorical_accuracy: 0.3131 - val_loss: 2.0801 - val_categorical_accuracy: 0.3360 - lr: 5.0000e-04\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 1.8785 - categorical_accuracy: 0.4294 - val_loss: 2.6026 - val_categorical_accuracy: 0.2514 - lr: 5.0000e-04\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 1.6396 - categorical_accuracy: 0.4522 - val_loss: 1.8974 - val_categorical_accuracy: 0.3135 - lr: 5.0000e-04\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 1.4803 - categorical_accuracy: 0.4528 - val_loss: 1.8695 - val_categorical_accuracy: 0.2748 - lr: 5.0000e-04\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 1.3676 - categorical_accuracy: 0.4611 - val_loss: 2.2428 - val_categorical_accuracy: 0.2559 - lr: 5.0000e-04\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 1.2683 - categorical_accuracy: 0.4766 - val_loss: 2.0763 - val_categorical_accuracy: 0.2901 - lr: 5.0000e-04\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 1.2019 - categorical_accuracy: 0.4874 - val_loss: 1.8527 - val_categorical_accuracy: 0.2964 - lr: 5.0000e-04\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 1.1411 - categorical_accuracy: 0.6321 - val_loss: 2.2217 - val_categorical_accuracy: 0.2622 - lr: 5.0000e-04\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 1.0772 - categorical_accuracy: 0.6686 - val_loss: 2.8476 - val_categorical_accuracy: 0.3459 - lr: 5.0000e-04\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 1.0267 - categorical_accuracy: 0.6882 - val_loss: 4.9362 - val_categorical_accuracy: 0.2658 - lr: 5.0000e-04\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.9900 - categorical_accuracy: 0.6958 - val_loss: 4.3174 - val_categorical_accuracy: 0.2730 - lr: 5.0000e-04\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.9493 - categorical_accuracy: 0.7074 - val_loss: 1.8954 - val_categorical_accuracy: 0.3000 - lr: 5.0000e-04\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.9185 - categorical_accuracy: 0.7113 - val_loss: 3.8384 - val_categorical_accuracy: 0.3351 - lr: 5.0000e-04\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 0.8934 - categorical_accuracy: 0.7137 - val_loss: 9.4690 - val_categorical_accuracy: 0.2505 - lr: 5.0000e-04\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8654 - categorical_accuracy: 0.7193 - val_loss: 1.9008 - val_categorical_accuracy: 0.3261 - lr: 5.0000e-04\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8355 - categorical_accuracy: 0.7279 - val_loss: 6.9133 - val_categorical_accuracy: 0.2586 - lr: 5.0000e-04\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8457 - categorical_accuracy: 0.7142 - val_loss: 2.8281 - val_categorical_accuracy: 0.3586 - lr: 5.0000e-04\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7943 - categorical_accuracy: 0.7359 - val_loss: 3.4989 - val_categorical_accuracy: 0.3414 - lr: 5.0000e-04\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8025 - categorical_accuracy: 0.7253 - val_loss: 2.3654 - val_categorical_accuracy: 0.3495 - lr: 5.0000e-04\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7652 - categorical_accuracy: 0.7390 - val_loss: 5.7129 - val_categorical_accuracy: 0.3541 - lr: 5.0000e-04\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7572 - categorical_accuracy: 0.7374 - val_loss: 2.3417 - val_categorical_accuracy: 0.3568 - lr: 5.0000e-04\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7618 - categorical_accuracy: 0.7316 - val_loss: 2.3452 - val_categorical_accuracy: 0.2333 - lr: 5.0000e-04\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7481 - categorical_accuracy: 0.7350 - val_loss: 4.0496 - val_categorical_accuracy: 0.3550 - lr: 5.0000e-04\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7340 - categorical_accuracy: 0.7396 - val_loss: 4.1646 - val_categorical_accuracy: 0.3378 - lr: 5.0000e-04\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 0.7209 - categorical_accuracy: 0.7407 - val_loss: 2.4357 - val_categorical_accuracy: 0.3324 - lr: 5.0000e-04\n",
      " *** -------END TRAIN-------- *** \n",
      " *** -------START EVAL-------- *** \n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.3820 - categorical_accuracy: 0.3304\n",
      " *** -------END EVAL-------- *** \n",
      " *** --------START TRAIN--------- *** \n",
      "SUBJECT EXCLUDED:  S04\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "Epoch 1/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.3063 - categorical_accuracy: 0.3178 - val_loss: 2.1267 - val_categorical_accuracy: 0.2333 - lr: 5.0000e-04\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.9098 - categorical_accuracy: 0.4261 - val_loss: 1.9223 - val_categorical_accuracy: 0.2410 - lr: 5.0000e-04\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.6619 - categorical_accuracy: 0.4352 - val_loss: 1.8791 - val_categorical_accuracy: 0.2368 - lr: 5.0000e-04\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.4913 - categorical_accuracy: 0.4356 - val_loss: 1.9978 - val_categorical_accuracy: 0.2034 - lr: 5.0000e-04\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.3674 - categorical_accuracy: 0.4525 - val_loss: 1.7962 - val_categorical_accuracy: 0.2316 - lr: 5.0000e-04\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.2700 - categorical_accuracy: 0.4751 - val_loss: 2.6503 - val_categorical_accuracy: 0.1991 - lr: 5.0000e-04\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.1981 - categorical_accuracy: 0.5095 - val_loss: 1.9902 - val_categorical_accuracy: 0.2051 - lr: 5.0000e-04\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 1.1344 - categorical_accuracy: 0.6435 - val_loss: 3.9088 - val_categorical_accuracy: 0.2308 - lr: 5.0000e-04\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.0799 - categorical_accuracy: 0.6675 - val_loss: 1.8995 - val_categorical_accuracy: 0.2444 - lr: 5.0000e-04\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.0295 - categorical_accuracy: 0.6868 - val_loss: 2.3669 - val_categorical_accuracy: 0.2009 - lr: 5.0000e-04\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.9923 - categorical_accuracy: 0.6954 - val_loss: 1.9505 - val_categorical_accuracy: 0.2453 - lr: 5.0000e-04\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.9655 - categorical_accuracy: 0.6998 - val_loss: 1.8639 - val_categorical_accuracy: 0.2504 - lr: 5.0000e-04\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.9155 - categorical_accuracy: 0.7190 - val_loss: 1.9158 - val_categorical_accuracy: 0.2436 - lr: 5.0000e-04\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8912 - categorical_accuracy: 0.7196 - val_loss: 2.0523 - val_categorical_accuracy: 0.2222 - lr: 5.0000e-04\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8568 - categorical_accuracy: 0.7308 - val_loss: 1.9649 - val_categorical_accuracy: 0.2521 - lr: 5.0000e-04\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8328 - categorical_accuracy: 0.7338 - val_loss: 2.4103 - val_categorical_accuracy: 0.2573 - lr: 5.0000e-04\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8310 - categorical_accuracy: 0.7292 - val_loss: 7.0015 - val_categorical_accuracy: 0.2513 - lr: 5.0000e-04\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7943 - categorical_accuracy: 0.7398 - val_loss: 2.4306 - val_categorical_accuracy: 0.2521 - lr: 5.0000e-04\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7838 - categorical_accuracy: 0.7390 - val_loss: 2.2222 - val_categorical_accuracy: 0.2393 - lr: 5.0000e-04\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7606 - categorical_accuracy: 0.7461 - val_loss: 4.9658 - val_categorical_accuracy: 0.2470 - lr: 5.0000e-04\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7598 - categorical_accuracy: 0.7410 - val_loss: 3.4966 - val_categorical_accuracy: 0.2376 - lr: 5.0000e-04\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7515 - categorical_accuracy: 0.7421 - val_loss: 3.3956 - val_categorical_accuracy: 0.2359 - lr: 5.0000e-04\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7212 - categorical_accuracy: 0.7512 - val_loss: 2.3667 - val_categorical_accuracy: 0.2624 - lr: 5.0000e-04\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7174 - categorical_accuracy: 0.7497 - val_loss: 2.3959 - val_categorical_accuracy: 0.2479 - lr: 5.0000e-04\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.7086 - categorical_accuracy: 0.7506 - val_loss: 3.2011 - val_categorical_accuracy: 0.2581 - lr: 5.0000e-04\n",
      " *** -------END TRAIN-------- *** \n",
      " *** -------START EVAL-------- *** \n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.1405 - categorical_accuracy: 0.2608\n",
      " *** -------END EVAL-------- *** \n",
      " *** --------START TRAIN--------- *** \n",
      "SUBJECT EXCLUDED:  S05\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "Epoch 1/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.4911 - categorical_accuracy: 0.2099 - val_loss: 2.3617 - val_categorical_accuracy: 0.2357 - lr: 2.5000e-04\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.2291 - categorical_accuracy: 0.3765 - val_loss: 2.2084 - val_categorical_accuracy: 0.3127 - lr: 2.5000e-04\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.0606 - categorical_accuracy: 0.4086 - val_loss: 2.1095 - val_categorical_accuracy: 0.3452 - lr: 2.5000e-04\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.9034 - categorical_accuracy: 0.4259 - val_loss: 2.0178 - val_categorical_accuracy: 0.2929 - lr: 2.5000e-04\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.7589 - categorical_accuracy: 0.4289 - val_loss: 1.9553 - val_categorical_accuracy: 0.2746 - lr: 2.5000e-04\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.6379 - categorical_accuracy: 0.4253 - val_loss: 1.9628 - val_categorical_accuracy: 0.2540 - lr: 2.5000e-04\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.5416 - categorical_accuracy: 0.4182 - val_loss: 2.0981 - val_categorical_accuracy: 0.2310 - lr: 2.5000e-04\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.4589 - categorical_accuracy: 0.4139 - val_loss: 1.8256 - val_categorical_accuracy: 0.2714 - lr: 2.5000e-04\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.3838 - categorical_accuracy: 0.4218 - val_loss: 1.8130 - val_categorical_accuracy: 0.3071 - lr: 2.5000e-04\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.3233 - categorical_accuracy: 0.4360 - val_loss: 1.8261 - val_categorical_accuracy: 0.3056 - lr: 2.5000e-04\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.2666 - categorical_accuracy: 0.4568 - val_loss: 1.7662 - val_categorical_accuracy: 0.3183 - lr: 2.5000e-04\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.2185 - categorical_accuracy: 0.4880 - val_loss: 1.7530 - val_categorical_accuracy: 0.3056 - lr: 2.5000e-04\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.1745 - categorical_accuracy: 0.6475 - val_loss: 1.7566 - val_categorical_accuracy: 0.3167 - lr: 2.5000e-04\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.1344 - categorical_accuracy: 0.6719 - val_loss: 1.7345 - val_categorical_accuracy: 0.3127 - lr: 2.5000e-04\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 1.1012 - categorical_accuracy: 0.6833 - val_loss: 1.7605 - val_categorical_accuracy: 0.3341 - lr: 2.5000e-04\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.0752 - categorical_accuracy: 0.6888 - val_loss: 3.6325 - val_categorical_accuracy: 0.2310 - lr: 2.5000e-04\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.0480 - categorical_accuracy: 0.6968 - val_loss: 2.2499 - val_categorical_accuracy: 0.3024 - lr: 2.5000e-04\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.0128 - categorical_accuracy: 0.7112 - val_loss: 1.9780 - val_categorical_accuracy: 0.2960 - lr: 2.5000e-04\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.9846 - categorical_accuracy: 0.7184 - val_loss: 1.7761 - val_categorical_accuracy: 0.3143 - lr: 2.5000e-04\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 0.9660 - categorical_accuracy: 0.7197 - val_loss: 1.9786 - val_categorical_accuracy: 0.3262 - lr: 2.5000e-04\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.9442 - categorical_accuracy: 0.7218 - val_loss: 3.4623 - val_categorical_accuracy: 0.2675 - lr: 2.5000e-04\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.9292 - categorical_accuracy: 0.7231 - val_loss: 2.7803 - val_categorical_accuracy: 0.2992 - lr: 2.5000e-04\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.9033 - categorical_accuracy: 0.7327 - val_loss: 1.9191 - val_categorical_accuracy: 0.2754 - lr: 2.5000e-04\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8840 - categorical_accuracy: 0.7350 - val_loss: 1.8408 - val_categorical_accuracy: 0.3159 - lr: 2.5000e-04\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.8708 - categorical_accuracy: 0.7353 - val_loss: 3.4342 - val_categorical_accuracy: 0.3103 - lr: 2.5000e-04\n",
      " *** -------END TRAIN-------- *** \n",
      " *** -------START EVAL-------- *** \n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.8240 - categorical_accuracy: 0.2908\n",
      " *** -------END EVAL-------- *** \n",
      " *** --------START TRAIN--------- *** \n",
      "SUBJECT EXCLUDED:  S06\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "Epoch 1/25\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 2.4925 - categorical_accuracy: 0.2274 - val_loss: 2.4025 - val_categorical_accuracy: 0.1693 - lr: 2.5000e-04\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.2287 - categorical_accuracy: 0.4031 - val_loss: 2.2506 - val_categorical_accuracy: 0.1813 - lr: 2.5000e-04\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.0549 - categorical_accuracy: 0.4460 - val_loss: 2.1428 - val_categorical_accuracy: 0.1887 - lr: 2.5000e-04\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.8929 - categorical_accuracy: 0.4542 - val_loss: 2.0296 - val_categorical_accuracy: 0.2453 - lr: 2.5000e-04\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.7494 - categorical_accuracy: 0.4581 - val_loss: 1.9566 - val_categorical_accuracy: 0.2887 - lr: 2.5000e-04\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.6346 - categorical_accuracy: 0.4572 - val_loss: 1.9130 - val_categorical_accuracy: 0.2553 - lr: 2.5000e-04\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.5423 - categorical_accuracy: 0.4475 - val_loss: 1.8457 - val_categorical_accuracy: 0.2873 - lr: 2.5000e-04\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 1.4607 - categorical_accuracy: 0.4435 - val_loss: 1.8121 - val_categorical_accuracy: 0.3047 - lr: 2.5000e-04\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 1.3896 - categorical_accuracy: 0.4477 - val_loss: 1.7637 - val_categorical_accuracy: 0.3053 - lr: 2.5000e-04\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.3217 - categorical_accuracy: 0.4644 - val_loss: 1.8034 - val_categorical_accuracy: 0.2947 - lr: 2.5000e-04\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 1.2642 - categorical_accuracy: 0.4812 - val_loss: 1.8027 - val_categorical_accuracy: 0.2967 - lr: 2.5000e-04\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.2121 - categorical_accuracy: 0.4986 - val_loss: 2.1258 - val_categorical_accuracy: 0.2833 - lr: 2.5000e-04\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.1704 - categorical_accuracy: 0.5087 - val_loss: 1.8550 - val_categorical_accuracy: 0.3013 - lr: 2.5000e-04\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.1318 - categorical_accuracy: 0.5344 - val_loss: 1.8007 - val_categorical_accuracy: 0.2960 - lr: 2.5000e-04\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.0912 - categorical_accuracy: 0.6745 - val_loss: 2.2756 - val_categorical_accuracy: 0.2927 - lr: 2.5000e-04\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.0565 - categorical_accuracy: 0.6934 - val_loss: 1.7012 - val_categorical_accuracy: 0.3380 - lr: 2.5000e-04\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.0357 - categorical_accuracy: 0.6957 - val_loss: 3.2343 - val_categorical_accuracy: 0.2567 - lr: 2.5000e-04\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.9962 - categorical_accuracy: 0.7124 - val_loss: 1.8763 - val_categorical_accuracy: 0.2993 - lr: 2.5000e-04\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.9773 - categorical_accuracy: 0.7117 - val_loss: 1.9459 - val_categorical_accuracy: 0.3107 - lr: 2.5000e-04\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.9479 - categorical_accuracy: 0.7214 - val_loss: 2.5402 - val_categorical_accuracy: 0.2973 - lr: 2.5000e-04\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.9278 - categorical_accuracy: 0.7238 - val_loss: 2.6323 - val_categorical_accuracy: 0.2773 - lr: 2.5000e-04\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.9144 - categorical_accuracy: 0.7220 - val_loss: 1.8541 - val_categorical_accuracy: 0.3333 - lr: 2.5000e-04\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.8882 - categorical_accuracy: 0.7297 - val_loss: 1.8796 - val_categorical_accuracy: 0.3127 - lr: 2.5000e-04\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.8841 - categorical_accuracy: 0.7244 - val_loss: 1.7735 - val_categorical_accuracy: 0.3367 - lr: 2.5000e-04\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.8606 - categorical_accuracy: 0.7302 - val_loss: 2.3144 - val_categorical_accuracy: 0.3047 - lr: 2.5000e-04\n",
      " *** -------END TRAIN-------- *** \n",
      " *** -------START EVAL-------- *** \n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.2732 - categorical_accuracy: 0.3277\n",
      " *** -------END EVAL-------- *** \n",
      " *** --------START TRAIN--------- *** \n",
      "SUBJECT EXCLUDED:  S07\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "Epoch 1/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 2.4921 - categorical_accuracy: 0.1978 - val_loss: 2.3339 - val_categorical_accuracy: 0.4150 - lr: 2.5000e-04\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 2.2344 - categorical_accuracy: 0.3470 - val_loss: 2.1726 - val_categorical_accuracy: 0.4412 - lr: 2.5000e-04\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 2.0655 - categorical_accuracy: 0.3876 - val_loss: 2.0483 - val_categorical_accuracy: 0.4358 - lr: 2.5000e-04\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.9032 - categorical_accuracy: 0.4197 - val_loss: 1.9119 - val_categorical_accuracy: 0.2704 - lr: 2.5000e-04\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.7572 - categorical_accuracy: 0.4246 - val_loss: 1.8440 - val_categorical_accuracy: 0.3675 - lr: 2.5000e-04\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.6375 - categorical_accuracy: 0.4232 - val_loss: 1.7775 - val_categorical_accuracy: 0.3675 - lr: 2.5000e-04\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 1.5501 - categorical_accuracy: 0.4175 - val_loss: 1.8034 - val_categorical_accuracy: 0.4467 - lr: 2.5000e-04\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.4763 - categorical_accuracy: 0.4049 - val_loss: 1.7872 - val_categorical_accuracy: 0.4471 - lr: 2.5000e-04\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 1.3942 - categorical_accuracy: 0.4056 - val_loss: 1.6407 - val_categorical_accuracy: 0.4383 - lr: 2.5000e-04\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.3354 - categorical_accuracy: 0.4209 - val_loss: 1.6767 - val_categorical_accuracy: 0.4462 - lr: 2.5000e-04\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.2776 - categorical_accuracy: 0.5371 - val_loss: 1.7263 - val_categorical_accuracy: 0.3858 - lr: 2.5000e-04\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.2185 - categorical_accuracy: 0.6581 - val_loss: 1.5252 - val_categorical_accuracy: 0.4433 - lr: 2.5000e-04\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 1.1805 - categorical_accuracy: 0.6685 - val_loss: 1.7381 - val_categorical_accuracy: 0.3142 - lr: 2.5000e-04\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.1446 - categorical_accuracy: 0.6749 - val_loss: 1.5970 - val_categorical_accuracy: 0.4104 - lr: 2.5000e-04\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.0962 - categorical_accuracy: 0.6996 - val_loss: 1.5811 - val_categorical_accuracy: 0.4096 - lr: 2.5000e-04\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.0714 - categorical_accuracy: 0.6966 - val_loss: 1.6526 - val_categorical_accuracy: 0.3750 - lr: 2.5000e-04\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.0462 - categorical_accuracy: 0.6954 - val_loss: 1.6128 - val_categorical_accuracy: 0.3967 - lr: 2.5000e-04\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 1.0063 - categorical_accuracy: 0.7125 - val_loss: 1.7745 - val_categorical_accuracy: 0.2887 - lr: 2.5000e-04\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.9853 - categorical_accuracy: 0.7085 - val_loss: 1.7236 - val_categorical_accuracy: 0.3379 - lr: 2.5000e-04\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.9683 - categorical_accuracy: 0.7074 - val_loss: 1.5964 - val_categorical_accuracy: 0.4096 - lr: 2.5000e-04\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.9416 - categorical_accuracy: 0.7153 - val_loss: 2.0940 - val_categorical_accuracy: 0.1708 - lr: 2.5000e-04\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.9178 - categorical_accuracy: 0.7185 - val_loss: 1.7764 - val_categorical_accuracy: 0.3229 - lr: 2.5000e-04\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.9109 - categorical_accuracy: 0.7116 - val_loss: 1.9827 - val_categorical_accuracy: 0.2271 - lr: 2.5000e-04\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.8841 - categorical_accuracy: 0.7204 - val_loss: 1.7993 - val_categorical_accuracy: 0.3454 - lr: 2.5000e-04\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.8652 - categorical_accuracy: 0.7238 - val_loss: 1.9874 - val_categorical_accuracy: 0.2579 - lr: 2.5000e-04\n",
      " *** -------END TRAIN-------- *** \n",
      " *** -------START EVAL-------- *** \n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0420 - categorical_accuracy: 0.2506\n",
      " *** -------END EVAL-------- *** \n",
      " *** --------START TRAIN--------- *** \n",
      "SUBJECT EXCLUDED:  S08\n",
      "Train Subject Trials:  33\n",
      "Test Subject Trials:  3\n",
      "Epoch 1/25\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 2.4734 - categorical_accuracy: 0.2565 - val_loss: 2.3980 - val_categorical_accuracy: 0.2024 - lr: 2.5000e-04\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 2.2066 - categorical_accuracy: 0.3955 - val_loss: 2.2147 - val_categorical_accuracy: 0.2667 - lr: 2.5000e-04\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 2.0243 - categorical_accuracy: 0.4424 - val_loss: 2.1039 - val_categorical_accuracy: 0.2536 - lr: 2.5000e-04\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.8488 - categorical_accuracy: 0.4595 - val_loss: 2.0161 - val_categorical_accuracy: 0.2583 - lr: 2.5000e-04\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.7120 - categorical_accuracy: 0.4569 - val_loss: 2.6170 - val_categorical_accuracy: 0.1631 - lr: 2.5000e-04\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 1.6014 - categorical_accuracy: 0.4681 - val_loss: 1.9085 - val_categorical_accuracy: 0.2190 - lr: 2.5000e-04\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.5159 - categorical_accuracy: 0.4570 - val_loss: 3.3707 - val_categorical_accuracy: 0.1679 - lr: 2.5000e-04\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.4320 - categorical_accuracy: 0.4421 - val_loss: 2.0730 - val_categorical_accuracy: 0.2071 - lr: 2.5000e-04\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 6s 11ms/step - loss: 1.3623 - categorical_accuracy: 0.4557 - val_loss: 1.8797 - val_categorical_accuracy: 0.2500 - lr: 2.5000e-04\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.3010 - categorical_accuracy: 0.4709 - val_loss: 2.0112 - val_categorical_accuracy: 0.2083 - lr: 2.5000e-04\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.2369 - categorical_accuracy: 0.4947 - val_loss: 1.7680 - val_categorical_accuracy: 0.2250 - lr: 2.5000e-04\n",
      "Epoch 12/25\n",
      "395/500 [======================>.......] - ETA: 1s - loss: 1.1935 - categorical_accuracy: 0.5025"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m train_dataloader, val_dataloader, test_dataloader \u001b[39m=\u001b[39m generate_data_split(subject)\n\u001b[1;32m     35\u001b[0m model\u001b[39m.\u001b[39mload_weights(\u001b[39m'\u001b[39m\u001b[39m./checkpoints/blank_state\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     38\u001b[0m     train_dataloader,\n\u001b[1;32m     39\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     40\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m     41\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m     42\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[1;32m     43\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m *** -------END TRAIN-------- *** \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m *** -------START EVAL-------- *** \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "steps_per_epoch = 500\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "subjects = ['S02','S03','S04','S05','S06','S07','S08','S09']\n",
    "\n",
    "\n",
    "model.save_weights('./checkpoints/blank_state')\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    print(\" *** --------START TRAIN--------- *** \")\n",
    "    print(\"SUBJECT EXCLUDED: \",subject)\n",
    "    \n",
    "    train_dataloader, val_dataloader, test_dataloader = generate_data_split(subject)\n",
    "\n",
    "    model.load_weights('./checkpoints/blank_state')\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataloader,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_dataloader,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    print(\" *** -------END TRAIN-------- *** \")\n",
    "    print(\" *** -------START EVAL-------- *** \")\n",
    "    \n",
    "    model.evaluate(test_dataloader, verbose=1)\n",
    "\n",
    "    print(\" *** -------END EVAL-------- *** \")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 0s 20ms/step - loss: 7.4180 - categorical_accuracy: 0.2594"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4923 - categorical_accuracy: 0.2656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.492281436920166, 0.2655773460865021]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataloader, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Subject Trials:  32\n",
      "Test Subject Trials:  4\n",
      "input_dim:  (30, 66)\n",
      "output_dim:  14\n",
      "14\n",
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S02\n",
      "Train Subject Trials:  32\n",
      "Test Subject Trials:  4\n",
      "Epoch 1/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 8.4796 - categorical_accuracy: 0.2081WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 11s 17ms/step - loss: 8.4678 - categorical_accuracy: 0.2082\n",
      "Epoch 2/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 2.1731 - categorical_accuracy: 0.2531WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 9s 17ms/step - loss: 2.1732 - categorical_accuracy: 0.2531\n",
      "Epoch 3/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.9201 - categorical_accuracy: 0.2686WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.9199 - categorical_accuracy: 0.2687\n",
      "Epoch 4/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.7386 - categorical_accuracy: 0.2890WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.7385 - categorical_accuracy: 0.2889\n",
      "Epoch 5/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.6056 - categorical_accuracy: 0.3183WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.6053 - categorical_accuracy: 0.3186\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.4901 - categorical_accuracy: 0.3880WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.4901 - categorical_accuracy: 0.3880\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.4061 - categorical_accuracy: 0.4259WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.4061 - categorical_accuracy: 0.4259\n",
      "Epoch 8/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.3554 - categorical_accuracy: 0.4448WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.3554 - categorical_accuracy: 0.4449\n",
      "Epoch 9/50\n",
      "497/500 [============================>.] - ETA: 0s - loss: 1.3163 - categorical_accuracy: 0.4602WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.3169 - categorical_accuracy: 0.4599\n",
      "Epoch 10/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.2808 - categorical_accuracy: 0.4742WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.2815 - categorical_accuracy: 0.4739\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2494 - categorical_accuracy: 0.4866WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.2494 - categorical_accuracy: 0.4866\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2191 - categorical_accuracy: 0.4972WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.2191 - categorical_accuracy: 0.4972\n",
      "Epoch 13/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.1865 - categorical_accuracy: 0.5063WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.1866 - categorical_accuracy: 0.5063\n",
      "Epoch 14/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.1556 - categorical_accuracy: 0.5132WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.1552 - categorical_accuracy: 0.5132\n",
      "Epoch 15/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 1.1250 - categorical_accuracy: 0.5194WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.1252 - categorical_accuracy: 0.5193\n",
      "Epoch 16/50\n",
      "497/500 [============================>.] - ETA: 0s - loss: 1.0968 - categorical_accuracy: 0.5232WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.0966 - categorical_accuracy: 0.5235\n",
      "Epoch 17/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0697 - categorical_accuracy: 0.5292WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.0702 - categorical_accuracy: 0.5289\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0446 - categorical_accuracy: 0.5366WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.0446 - categorical_accuracy: 0.5366\n",
      "Epoch 19/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 1.0244 - categorical_accuracy: 0.5458WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.0240 - categorical_accuracy: 0.5461\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0040 - categorical_accuracy: 0.5569WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 1.0040 - categorical_accuracy: 0.5569\n",
      "Epoch 21/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9828 - categorical_accuracy: 0.5704WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.9825 - categorical_accuracy: 0.5706\n",
      "Epoch 22/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.9625 - categorical_accuracy: 0.5862WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.9625 - categorical_accuracy: 0.5862\n",
      "Epoch 23/50\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.9400 - categorical_accuracy: 0.6030WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.9391 - categorical_accuracy: 0.6037\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9181 - categorical_accuracy: 0.6174WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.9181 - categorical_accuracy: 0.6174\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8934 - categorical_accuracy: 0.6330WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.8934 - categorical_accuracy: 0.6330\n",
      "Epoch 26/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.8681 - categorical_accuracy: 0.6478WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.8679 - categorical_accuracy: 0.6479\n",
      "Epoch 27/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.8431 - categorical_accuracy: 0.6597WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.8431 - categorical_accuracy: 0.6597\n",
      "Epoch 28/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.8236 - categorical_accuracy: 0.6715WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.8229 - categorical_accuracy: 0.6718\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7964 - categorical_accuracy: 0.6849WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.7964 - categorical_accuracy: 0.6849\n",
      "Epoch 30/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7709 - categorical_accuracy: 0.6978WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.7716 - categorical_accuracy: 0.6975\n",
      "Epoch 31/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7450 - categorical_accuracy: 0.7103WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.7448 - categorical_accuracy: 0.7104\n",
      "Epoch 32/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.7224 - categorical_accuracy: 0.7219WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.7223 - categorical_accuracy: 0.7219\n",
      "Epoch 33/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6962 - categorical_accuracy: 0.7331WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.6965 - categorical_accuracy: 0.7329\n",
      "Epoch 34/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6696 - categorical_accuracy: 0.7452WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.6696 - categorical_accuracy: 0.7452\n",
      "Epoch 35/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6465 - categorical_accuracy: 0.7563WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.6466 - categorical_accuracy: 0.7562\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6249 - categorical_accuracy: 0.7662WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.6249 - categorical_accuracy: 0.7662\n",
      "Epoch 37/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.6053 - categorical_accuracy: 0.7760WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.6061 - categorical_accuracy: 0.7756\n",
      "Epoch 38/50\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.5867 - categorical_accuracy: 0.7848WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.5863 - categorical_accuracy: 0.7850\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5720 - categorical_accuracy: 0.7917WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.5720 - categorical_accuracy: 0.7917\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5582 - categorical_accuracy: 0.7991WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.5582 - categorical_accuracy: 0.7991\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5408 - categorical_accuracy: 0.8061WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.5408 - categorical_accuracy: 0.8061\n",
      "Epoch 42/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5564 - categorical_accuracy: 0.7992WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.5577 - categorical_accuracy: 0.7987\n",
      "Epoch 43/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.5497 - categorical_accuracy: 0.8038WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.5492 - categorical_accuracy: 0.8040\n",
      "Epoch 44/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.4894 - categorical_accuracy: 0.8297WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4890 - categorical_accuracy: 0.8298\n",
      "Epoch 45/50\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.4664 - categorical_accuracy: 0.8392WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4669 - categorical_accuracy: 0.8390\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4465 - categorical_accuracy: 0.8472WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4465 - categorical_accuracy: 0.8472\n",
      "Epoch 47/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.4278 - categorical_accuracy: 0.8552WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4282 - categorical_accuracy: 0.8550\n",
      "Epoch 48/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.4171 - categorical_accuracy: 0.8593WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4170 - categorical_accuracy: 0.8595\n",
      "Epoch 49/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.4017 - categorical_accuracy: 0.8663WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4015 - categorical_accuracy: 0.8664\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3836 - categorical_accuracy: 0.8737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.3836 - categorical_accuracy: 0.8737\n",
      " *** -------END-------- *** \n",
      " *** --------START--------- *** \n",
      "SUBJECT EXCLUDED:  S03\n",
      "Train Subject Trials:  31\n",
      "Test Subject Trials:  5\n",
      "Epoch 1/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.5966 - categorical_accuracy: 0.8091WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.5963 - categorical_accuracy: 0.8092\n",
      "Epoch 2/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.5172 - categorical_accuracy: 0.8268WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.5172 - categorical_accuracy: 0.8268\n",
      "Epoch 3/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.4869 - categorical_accuracy: 0.8363WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4870 - categorical_accuracy: 0.8363\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4806 - categorical_accuracy: 0.8369WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4806 - categorical_accuracy: 0.8369\n",
      "Epoch 5/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.5238 - categorical_accuracy: 0.8174WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.5241 - categorical_accuracy: 0.8173\n",
      "Epoch 6/50\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.4749 - categorical_accuracy: 0.8390WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4751 - categorical_accuracy: 0.8389\n",
      "Epoch 7/50\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.4119 - categorical_accuracy: 0.8629WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4121 - categorical_accuracy: 0.8628\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4079 - categorical_accuracy: 0.8641WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.4079 - categorical_accuracy: 0.8641\n",
      "Epoch 9/50\n",
      "476/500 [===========================>..] - ETA: 0s - loss: 0.3941 - categorical_accuracy: 0.8682"
     ]
    }
   ],
   "source": [
    "# input_shape = (30,66)\n",
    "# input_shape = train_features.shape\n",
    "\n",
    "# train_features = train_features.to_numpy()\n",
    "# train_features = train_features.reshape((train_features.shape[0], train_features.shape[1], 1))\n",
    "# input_shape = train_features.shape\n",
    "train_dataloader, test_dataloader = generate_data_split(subject)\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "input_shape = train_features.shape[1:]\n",
    "output_dim = train_labels.shape[2]\n",
    "\n",
    "print(\"input_dim: \",input_shape)\n",
    "print(\"output_dim: \",output_dim)\n",
    "\n",
    "\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    output_dim,\n",
    "    head_size=256,\n",
    "    num_heads=2,\n",
    "    ff_dim=512,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[256,128],\n",
    "    mlp_dropout=0.5,\n",
    "    dropout=0.3,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")\n",
    "# # # # model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "epochs = 50\n",
    "# steps_per_epoch = train_dataloader.__len__()//1\n",
    "# print(\"steps_per\", steps_per_epoch)\n",
    "\n",
    "\n",
    "subjects = ['S02','S03','S04','S05','S06','S07','S08','S09']\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    print(\" *** --------START--------- *** \")\n",
    "    print(\"SUBJECT EXCLUDED: \",subject)\n",
    "    \n",
    "    train_dataloader, test_dataloader = generate_data_split(subject)\n",
    "\n",
    "    model.fit(\n",
    "        train_dataloader,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=500\n",
    "#         validation_data = test_dataloader\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\" *** -------END-------- *** \")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "## Pytorch dataloader implementation\n",
    "\n",
    "# def gen(torch_loader):\n",
    "#     for x,y in torch_loader:\n",
    "#         yield (x,y)\n",
    "\n",
    "# train = gen(train_dataloader)\n",
    "\n",
    "# epochs = 300\n",
    "# steps_per_epoch = train_dataloader.__len__()//5\n",
    "# print(\"steps_per\", steps_per_epoch)\n",
    "\n",
    "# model.fit(\n",
    "#     train,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=callbacks,\n",
    "#     steps_per_epoch=steps_per_epoch\n",
    "# )\n",
    "\n",
    "# # model.evaluate(x_test, y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q -U keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  (30, 71)\n",
      "output_dim:  14\n",
      "INFO:tensorflow:Reloading Tuner from ./intro_to_kt/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# import keras_tuner as kt\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "# input_shape = train_features.shape[1:]\n",
    "# output_dim = train_labels.shape[2]\n",
    "\n",
    "# print(\"input_dim: \",input_shape)\n",
    "# print(\"output_dim: \",output_dim)\n",
    "\n",
    "\n",
    "# def model_builder(hp):\n",
    "    \n",
    "    \n",
    "#     hp_headsize = hp.Int('units', min_value=16, max_value=512, step=16)\n",
    "#     hp_numheads = hp.Int('units', min_value=2, max_value=16, step=2)\n",
    "#     hp_ff_dim = hp.Int('units', min_value=1, max_value=512, step=16)\n",
    "#     hp_num_transformer_blocks = hp.Int('units', min_value=1, max_value=16, step=2)\n",
    "\n",
    "#     model = build_model(\n",
    "#     input_shape,\n",
    "#     output_dim,\n",
    "#     head_size=hp_headsize,\n",
    "#     num_heads=hp_numheads,\n",
    "#     ff_dim=hp_ff_dim,\n",
    "#     num_transformer_blocks=hp_num_transformer_blocks,\n",
    "#     mlp_units=[128],\n",
    "#     mlp_dropout=0.4,\n",
    "#     dropout=0.25,\n",
    "#     )\n",
    "\n",
    "#     model.compile(\n",
    "#         loss=\"categorical_crossentropy\",\n",
    "#         optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#         metrics=[\"categorical_accuracy\"],\n",
    "#     )\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# tuner = kt.Hyperband(model_builder,\n",
    "#                      objective='val_accuracy',\n",
    "#                      max_epochs=10,\n",
    "#                      factor=3,\n",
    "#                      project_name='intro_to_kt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search(train_dataloader, epochs=10, steps_per_epoch=500, callbacks=[stop_early])\n",
    "\n",
    "# # Get the optimal hyperparameters\n",
    "# best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "# layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "# is {best_hps.get('learning_rate')}.\n",
    "# \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9062 - categorical_accuracy: 0.6734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9061856865882874, 0.6734204888343811]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataloader, verbose=1)\n",
    "\n",
    "# test_features, test_labels = next(iter(test_dataloader))\n",
    "\n",
    "# y_pred = model(test_features)\n",
    "\n",
    "# relu = nn.ReLU()\n",
    "\n",
    "\n",
    "# for idx,y in enumerate(y_pred) :\n",
    "#     for i,sample in enumerate(y):\n",
    "#         print(np.argmax(test_labels[idx][i].numpy()))\n",
    "#         print(np.argmax(sample))\n",
    "#         print('-----')\n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/progress_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (71,) when attempting to restore variable with shape (66,) and name layer_with_weights-0/beta/.ATTRIBUTES/VARIABLE_VALUE.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [117], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Restore the weights\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints/progress_v1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/training/saving/saveable_object_util.py:135\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    132\u001b[0m   assigned_variable \u001b[38;5;241m=\u001b[39m resource_variable_ops\u001b[38;5;241m.\u001b[39mshape_safe_assign_variable_handle(\n\u001b[1;32m    133\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_op, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape, restored_tensor)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived incompatible tensor with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestored_tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen attempting to restore variable with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[0;31mValueError\u001b[0m: Received incompatible tensor with shape (71,) when attempting to restore variable with shape (66,) and name layer_with_weights-0/beta/.ATTRIBUTES/VARIABLE_VALUE."
     ]
    }
   ],
   "source": [
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/progress_v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
