{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing\n",
    "import glob\n",
    "\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CSV files list from a folder\n",
    "train_path = './ProcessedDatasets/Knot_Tying/TrainSet'\n",
    "test_path = './ProcessedDatasets/Knot_Tying/TestSet'\n",
    "train_csv_files = glob.glob(train_path + \"/*.csv\")\n",
    "test_csv_files = glob.glob(test_path + \"/*.csv\")\n",
    "\n",
    "# Read each CSV file into DataFrame\n",
    "# This creates a list of dataframes\n",
    "train_df_list = (pd.read_csv(file) for file in train_csv_files)\n",
    "test_df_list = (pd.read_csv(file) for file in test_csv_files)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "train_df   = pd.concat(train_df_list, ignore_index=True)\n",
    "test_df   = pd.concat(test_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " ...\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]]\n",
      "[[0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " ...\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "\n",
    "\n",
    "train_labels= train_df.pop('label')\n",
    "train_features = train_df\n",
    "\n",
    "test_labels= test_df.pop('label')\n",
    "test_features = test_df\n",
    "\n",
    "train_labels = lb.fit_transform(train_labels)\n",
    "test_labels = lb.fit_transform(test_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41013, 6)\n",
      "(10845, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
